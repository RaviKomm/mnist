{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2125666e",
   "metadata": {},
   "source": [
    "## Step 1: Import Necessary Libraries\n",
    "We first import the required libraries for building and training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150dffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel import DataParallel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52024b5b",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Device\n",
    "We use CUDA (GPU) if available, otherwise default to CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7631f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c7965",
   "metadata": {},
   "source": [
    "## Step 3: Define Data Transformations and Load MNIST Dataset\n",
    "The MNIST dataset is used for both classification and generation tasks. We apply normalization as a preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b79dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98dc0cb",
   "metadata": {},
   "source": [
    "## Step 4: Define Classifier Model\n",
    "The classifier is a simple feedforward neural network that takes flattened MNIST images as input and predicts class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45893b19",
   "metadata": {},
   "source": [
    "## Step 5: Define DCGAN Generator\n",
    "The generator creates fake MNIST images from random noise using transposed convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 128, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 100, 1, 1)\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9faf222",
   "metadata": {},
   "source": [
    "## Step 6: Define DCGAN Critic (Discriminator)\n",
    "The critic evaluates both real and fake MNIST images using convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32913b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 1, kernel_size=7, stride=1, padding=0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.critic(x).view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbe1f5",
   "metadata": {},
   "source": [
    "## Step 7: Gradient Penalty for WGAN-GP\n",
    "To improve GAN stability, we compute the gradient penalty for interpolated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df269708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real_images, fake_images):\n",
    "    batch_size, c, h, w = real_images.shape\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1).to(device)\n",
    "    interpolated_images = epsilon * real_images + (1 - epsilon) * fake_images\n",
    "    interpolated_images.requires_grad_(True)\n",
    "\n",
    "    interpolated_outputs = critic(interpolated_images)\n",
    "    grad_outputs = torch.ones_like(interpolated_outputs, device=device)\n",
    "\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=interpolated_outputs,\n",
    "        inputs=interpolated_images,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dbcd39",
   "metadata": {},
   "source": [
    "## Step 8: Initialize Models and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e983e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier().to(device)\n",
    "generator = Generator().to(device)\n",
    "critic = Critic().to(device)\n",
    "\n",
    "classifier = DataParallel(classifier)\n",
    "generator = DataParallel(generator)\n",
    "critic = DataParallel(critic)\n",
    "\n",
    "optimizer_classifier = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_critic = optim.Adam(critic.parameters(), lr=0.0002)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
